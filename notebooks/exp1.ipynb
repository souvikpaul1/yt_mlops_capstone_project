{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee53e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5a16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ef42bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every great gangster movie has under-currents ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just saw this film last night, and I have to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mildly entertaining if one neglec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino's partner in crime Roger Ava...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I sat through this on TV hoping because of the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Every great gangster movie has under-currents ...  positive\n",
       "1  I just saw this film last night, and I have to...  positive\n",
       "2  This film is mildly entertaining if one neglec...  negative\n",
       "3  Quentin Tarantino's partner in crime Roger Ava...  negative\n",
       "4  I sat through this on TV hoping because of the...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b111eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceca068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie under current human...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino s partner crime roger avary ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time but dear g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  every great gangster movie under current human...  positive\n",
       "1  saw film last night say loved every minute tak...  positive\n",
       "2  film mildly entertaining one neglect acknowled...  negative\n",
       "3  quentin tarantino s partner crime roger avary ...  negative\n",
       "4  sat tv hoping name would worth time but dear g...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5b83e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    269\n",
       "positive    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a32e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a628e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    269\n",
       "positive    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0f634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie under current human...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino s partner crime roger avary ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time but dear g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  every great gangster movie under current human...          1\n",
       "1  saw film last night say loved every minute tak...          1\n",
       "2  film mildly entertaining one neglect acknowled...          0\n",
       "3  quentin tarantino s partner crime roger avary ...          0\n",
       "4  sat tv hoping name would worth time but dear g...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the purpose of count vectorizer?\n",
    "# CountVectorizer converts a collection of text documents to a matrix of token counts. \n",
    "# It is used to convert the text data into a format that can be used by machine learning algorithms.\n",
    "# It creates a sparse matrix where each row represents a document and each column represents a token (word).\n",
    "# The value in each cell of the matrix represents the count of the token in the document.\n",
    "# The CountVectorizer is used to convert the text data into a format that can be used by machine learning algorithms.\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824593fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 8, 0, 3, 1, 0, 0, 0, 0, 0,\n",
       "        0, 2, 1, 1, 0, 5, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 4, 1, 0, 2, 1, 0, 0,\n",
       "        0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if I want to see 1st record of the vectorizer\n",
    "#other options to count vectorizer\n",
    "#vectorizer.get_feature_names_out() \n",
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56aec14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acting', 'actor', 'actually', 'all', 'almost', 'also', 'and',\n",
       "       'another', 'back', 'bad', 'best', 'better', 'book', 'br', 'can',\n",
       "       'character', 'come', 'could', 'day', 'director', 'done', 'end',\n",
       "       'even', 'ever', 'every', 'fact', 'feel', 'film', 'find', 'first',\n",
       "       'get', 'give', 'go', 'going', 'good', 'great', 'guy', 'horror',\n",
       "       'interesting', 'it', 'know', 'life', 'like', 'little', 'long',\n",
       "       'look', 'lot', 'love', 'made', 'make', 'man', 'many', 'movie',\n",
       "       'much', 'must', 'never', 'new', 'nothing', 'old', 'one', 'part',\n",
       "       'people', 'performance', 'play', 'plot', 'pretty', 'quite', 'real',\n",
       "       'really', 'role', 'say', 'scene', 'see', 'seems', 'seen', 'show',\n",
       "       'something', 'still', 'story', 'take', 'that', 'the', 'there',\n",
       "       'thing', 'think', 'this', 'though', 'time', 'two', 'want', 'watch',\n",
       "       'watching', 'way', 'well', 'whole', 'woman', 'work', 'world',\n",
       "       'would', 'year'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5722ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc677f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\souvik\\anaconda3\\envs\\atlas\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\souvik\\anaconda3\\envs\\atlas\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=4e6f147b-df27-4ef6-b4ad-e8389487ab8d&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=670008f7f463f53ae2abedcd5add6e69fe6113a79fd672daf00f1113b05db471\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as souvikpaul425\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as souvikpaul425\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"souvikpaul425/yt_mlops_capstone_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"souvikpaul425/yt_mlops_capstone_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository souvikpaul425/yt_mlops_capstone_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository souvikpaul425/yt_mlops_capstone_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/28 14:49:49 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Baseline V2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/815f9a20411b4f04bf31d4242d566725', creation_time=1748423990194, experiment_id='4', last_update_time=1748423990194, lifecycle_stage='active', name='Logistic Regression Baseline V2', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/souvikpaul425/yt_mlops_capstone_project.mlflow/')\n",
    "dagshub.init(repo_owner='souvikpaul425', repo_name='yt_mlops_capstone_project', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b0d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 14:58:13,734 - INFO - Starting MLflow run...\n",
      "2025-05-28 14:58:14,106 - INFO - Logging preprocessing parameters...\n",
      "2025-05-28 14:58:15,168 - INFO - Initializing Logistic Regression model...\n",
      "2025-05-28 14:58:15,169 - INFO - Fitting the model...\n",
      "2025-05-28 14:58:15,226 - INFO - Model training complete.\n",
      "2025-05-28 14:58:15,227 - INFO - Logging model parameters...\n",
      "2025-05-28 14:58:15,551 - INFO - Making predictions...\n",
      "2025-05-28 14:58:15,551 - INFO - Calculating evaluation metrics...\n",
      "2025-05-28 14:58:15,566 - INFO - Logging evaluation metrics...\n",
      "2025-05-28 14:58:16,971 - INFO - Saving and logging the model...\n",
      "2025/05/28 14:58:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025-05-28 14:58:37,275 - INFO - Model training and logging completed in 23.17 seconds.\n",
      "2025-05-28 14:58:37,277 - INFO - Accuracy: 0.66\n",
      "2025-05-28 14:58:37,277 - INFO - Precision: 0.6666666666666666\n",
      "2025-05-28 14:58:37,281 - INFO - Recall: 0.64\n",
      "2025-05-28 14:58:37,281 - INFO - F1 Score: 0.6530612244897959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run painted-eel-603 at: https://dagshub.com/souvikpaul425/yt_mlops_capstone_project.mlflow/#/experiments/4/runs/a34122742b844c36ae19535c876592f0\n",
      "üß™ View experiment at: https://dagshub.com/souvikpaul425/yt_mlops_capstone_project.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run(): \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 100)\n",
    "        mlflow.log_param(\"test_size\", 0.20)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fb56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:06:18,252 - INFO - Starting MLflow run...\n",
      "2025-05-28 15:06:18,858 - INFO - Logging preprocessing parameters...\n",
      "2025-05-28 15:06:19,911 - INFO - Defining hyperparameter grid for Logistic Regression...\n",
      "2025-05-28 15:06:19,911 - INFO - Initializing GridSearchCV...\n",
      "2025-05-28 15:06:19,911 - INFO - Fitting the model with GridSearchCV...\n",
      "2025-05-28 15:06:36,761 - INFO - Grid search complete.\n",
      "2025-05-28 15:06:36,761 - INFO - Logging best hyperparameters from grid search...\n",
      "2025-05-28 15:06:37,475 - INFO - Making predictions with the best model...\n",
      "2025-05-28 15:06:37,475 - INFO - Calculating evaluation metrics...\n",
      "2025-05-28 15:06:37,498 - INFO - Logging evaluation metrics...\n",
      "2025-05-28 15:06:38,895 - INFO - Saving and logging the best model...\n",
      "2025/05/28 15:06:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025-05-28 15:06:47,979 - INFO - Model training and logging completed in 29.12 seconds.\n",
      "2025-05-28 15:06:47,980 - INFO - Accuracy: 0.74\n",
      "2025-05-28 15:06:47,981 - INFO - Precision: 0.7727272727272727\n",
      "2025-05-28 15:06:47,982 - INFO - Recall: 0.68\n",
      "2025-05-28 15:06:47,983 - INFO - F1 Score: 0.723404255319149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run amusing-shoat-37 at: https://dagshub.com/souvikpaul425/yt_mlops_capstone_project.mlflow/#/experiments/4/runs/4115e9f0989f49c18c5cc8a168027774\n",
      "üß™ View experiment at: https://dagshub.com/souvikpaul425/yt_mlops_capstone_project.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run(): \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 100)\n",
    "        mlflow.log_param(\"test_size\", 0.20)\n",
    "\n",
    "        logging.info(\"Defining hyperparameter grid for Logistic Regression...\")\n",
    "        param_grid = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'solver': ['liblinear'],  # 'liblinear' supports both l1 and l2\n",
    "            'max_iter': [1000]\n",
    "        }\n",
    "\n",
    "        logging.info(\"Initializing GridSearchCV...\")\n",
    "        grid_search = GridSearchCV(\n",
    "            LogisticRegression(),\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        logging.info(\"Fitting the model with GridSearchCV...\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        logging.info(\"Grid search complete.\")\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        logging.info(\"Logging best hyperparameters from grid search...\")\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression (GridSearchCV)\")\n",
    "\n",
    "        logging.info(\"Making predictions with the best model...\")\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the best model...\")\n",
    "        mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa891193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2025-05-28 15:06:47,980 - INFO - Accuracy: 0.74\n",
    "2025-05-28 15:06:47,981 - INFO - Precision: 0.7727272727272727\n",
    "2025-05-28 15:06:47,982 - INFO - Recall: 0.68\n",
    "2025-05-28 15:06:47,983 - INFO - F1 Score: 0.723404255319149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439b445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
